{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Dense,Dropout,BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for random number generators for reproducable results\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = pyreadr.read_r(\"/home/shanmukh/Documents/IICT/tep-fault-detection/dataset/TEP_FaultFree_Training.RData\")\n",
    "df = data['fault_free_training']\n",
    "training_data = df.drop([\"faultNumber\",\"simulationRun\",\"sample\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Normalization\n",
    "# 0 mean \n",
    "# 1 std\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(training_data)\n",
    "training_data = scaler.transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Autoencoder model\n",
    "def autoencoder(dropout=0.0,regularization = 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,input_dim=52,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(64,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(32, name='latent_space'))\n",
    "    \n",
    "    model.add(Dense(64,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(dropout))\n",
    "    model.add(Dense(128,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(dropout))\n",
    "    model.add(Dense(52))\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/1000\n",
      "200000/200000 [==============================] - 15s 75us/step - loss: 0.1986 - mean_squared_error: 0.1986 - val_loss: 0.1083 - val_mean_squared_error: 0.1083\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10826, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-01-0.11.hdf5\n",
      "Epoch 2/1000\n",
      "200000/200000 [==============================] - 13s 65us/step - loss: 0.0995 - mean_squared_error: 0.0995 - val_loss: 0.0912 - val_mean_squared_error: 0.0912\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10826 to 0.09121, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-02-0.09.hdf5\n",
      "Epoch 3/1000\n",
      "200000/200000 [==============================] - 13s 65us/step - loss: 0.0970 - mean_squared_error: 0.0970 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09121 to 0.08985, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-03-0.09.hdf5\n",
      "Epoch 4/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0962 - mean_squared_error: 0.0962 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08985\n",
      "Epoch 5/1000\n",
      "200000/200000 [==============================] - 13s 66us/step - loss: 0.0959 - mean_squared_error: 0.0959 - val_loss: 0.0897 - val_mean_squared_error: 0.0897\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08985 to 0.08972, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-05-0.09.hdf5\n",
      "Epoch 6/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0956 - mean_squared_error: 0.0956 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.08972 to 0.08933, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-06-0.09.hdf5\n",
      "Epoch 7/1000\n",
      "200000/200000 [==============================] - 13s 66us/step - loss: 0.0953 - mean_squared_error: 0.0953 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08933 to 0.08930, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-07-0.09.hdf5\n",
      "Epoch 8/1000\n",
      "200000/200000 [==============================] - 13s 66us/step - loss: 0.0951 - mean_squared_error: 0.0951 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08930\n",
      "Epoch 9/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0949 - mean_squared_error: 0.0949 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08930 to 0.08904, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-09-0.09.hdf5\n",
      "Epoch 10/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0947 - mean_squared_error: 0.0947 - val_loss: 0.0889 - val_mean_squared_error: 0.0889\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08904 to 0.08893, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-10-0.09.hdf5\n",
      "Epoch 11/1000\n",
      "200000/200000 [==============================] - 13s 64us/step - loss: 0.0947 - mean_squared_error: 0.0947 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.08893\n",
      "Epoch 12/1000\n",
      "200000/200000 [==============================] - 14s 69us/step - loss: 0.0946 - mean_squared_error: 0.0946 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08893 to 0.08870, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-12-0.09.hdf5\n",
      "Epoch 13/1000\n",
      "200000/200000 [==============================] - 13s 64us/step - loss: 0.0946 - mean_squared_error: 0.0946 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08870 to 0.08860, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-13-0.09.hdf5\n",
      "Epoch 14/1000\n",
      "200000/200000 [==============================] - 13s 66us/step - loss: 0.0944 - mean_squared_error: 0.0944 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08860 to 0.08849, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-14-0.09.hdf5\n",
      "Epoch 15/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0944 - mean_squared_error: 0.0944 - val_loss: 0.0883 - val_mean_squared_error: 0.0883\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08849 to 0.08829, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-15-0.09.hdf5\n",
      "Epoch 16/1000\n",
      "200000/200000 [==============================] - 13s 66us/step - loss: 0.0943 - mean_squared_error: 0.0943 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08829\n",
      "Epoch 17/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0942 - mean_squared_error: 0.0942 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08829\n",
      "Epoch 18/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0943 - mean_squared_error: 0.0943 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.08829\n",
      "Epoch 19/1000\n",
      "200000/200000 [==============================] - 14s 70us/step - loss: 0.0941 - mean_squared_error: 0.0941 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.08829\n",
      "Epoch 20/1000\n",
      "200000/200000 [==============================] - 14s 70us/step - loss: 0.0941 - mean_squared_error: 0.0941 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08829\n",
      "Epoch 21/1000\n",
      "200000/200000 [==============================] - 13s 65us/step - loss: 0.0930 - mean_squared_error: 0.0930 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.08829 to 0.08656, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-21-0.09.hdf5\n",
      "Epoch 22/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0930 - mean_squared_error: 0.0930 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08656\n",
      "Epoch 23/1000\n",
      "200000/200000 [==============================] - 14s 69us/step - loss: 0.0931 - mean_squared_error: 0.0931 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08656\n",
      "Epoch 24/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0929 - mean_squared_error: 0.0929 - val_loss: 0.0865 - val_mean_squared_error: 0.0865\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.08656 to 0.08654, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-24-0.09.hdf5\n",
      "Epoch 25/1000\n",
      "200000/200000 [==============================] - 13s 66us/step - loss: 0.0930 - mean_squared_error: 0.0930 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08654\n",
      "Epoch 26/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0930 - mean_squared_error: 0.0930 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.08654\n",
      "Epoch 27/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.08654 to 0.08630, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-27-0.09.hdf5\n",
      "Epoch 28/1000\n",
      "200000/200000 [==============================] - 14s 69us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08630\n",
      "Epoch 29/1000\n",
      "200000/200000 [==============================] - 14s 69us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08630 to 0.08630, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-29-0.09.hdf5\n",
      "Epoch 30/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.08630 to 0.08628, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-30-0.09.hdf5\n",
      "Epoch 31/1000\n",
      "200000/200000 [==============================] - 14s 70us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08628\n",
      "Epoch 32/1000\n",
      "200000/200000 [==============================] - 14s 71us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08628\n",
      "Epoch 33/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08628 to 0.08627, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-33-0.09.hdf5\n",
      "Epoch 34/1000\n",
      "200000/200000 [==============================] - 13s 65us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08627 to 0.08626, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-34-0.09.hdf5\n",
      "Epoch 35/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08626\n",
      "Epoch 36/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08626 to 0.08626, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-36-0.09.hdf5\n",
      "Epoch 37/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08626\n",
      "Epoch 38/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08626 to 0.08626, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-38-0.09.hdf5\n",
      "Epoch 39/1000\n",
      "200000/200000 [==============================] - 14s 70us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08626\n",
      "Epoch 40/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08626\n",
      "Epoch 41/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08626\n",
      "Epoch 42/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08626\n",
      "Epoch 43/1000\n",
      "200000/200000 [==============================] - 14s 71us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08626 to 0.08626, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-43-0.09.hdf5\n",
      "Epoch 44/1000\n",
      "200000/200000 [==============================] - 12s 58us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08626\n",
      "Epoch 45/1000\n",
      "200000/200000 [==============================] - 10s 50us/step - loss: 0.0925 - mean_squared_error: 0.0925 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08626\n",
      "Epoch 46/1000\n",
      "200000/200000 [==============================] - 13s 63us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08626\n",
      "Epoch 47/1000\n",
      "200000/200000 [==============================] - 12s 61us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08626\n",
      "Epoch 48/1000\n",
      "200000/200000 [==============================] - 11s 54us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08626\n",
      "Epoch 49/1000\n",
      "200000/200000 [==============================] - 12s 59us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08626\n",
      "Epoch 50/1000\n",
      "200000/200000 [==============================] - 12s 59us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08626\n",
      "Epoch 51/1000\n",
      "200000/200000 [==============================] - 12s 61us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08626\n",
      "Epoch 52/1000\n",
      "200000/200000 [==============================] - 11s 56us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.08626\n",
      "Epoch 53/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.08626\n",
      "Epoch 54/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08626\n",
      "Epoch 55/1000\n",
      "200000/200000 [==============================] - 13s 63us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08626 to 0.08625, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-55-0.09.hdf5\n",
      "Epoch 56/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.08625\n",
      "Epoch 57/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.08625\n",
      "Epoch 58/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.08625\n",
      "Epoch 59/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.08625\n",
      "Epoch 60/1000\n",
      "200000/200000 [==============================] - 12s 58us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.08625\n",
      "Epoch 61/1000\n",
      "200000/200000 [==============================] - 13s 64us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.08625\n",
      "Epoch 62/1000\n",
      "200000/200000 [==============================] - 13s 67us/step - loss: 0.0927 - mean_squared_error: 0.0927 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.08625\n",
      "Epoch 63/1000\n",
      "200000/200000 [==============================] - 14s 69us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.08625\n",
      "Epoch 64/1000\n",
      "200000/200000 [==============================] - 11s 57us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08625\n",
      "Epoch 65/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08625\n",
      "Epoch 66/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08625\n",
      "Epoch 67/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08625\n",
      "Epoch 68/1000\n",
      "200000/200000 [==============================] - 14s 68us/step - loss: 0.0926 - mean_squared_error: 0.0926 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cb005e358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = autoencoder()\n",
    "model.compile(optimizer=Adam(lr=0.001),loss=\"mse\",metrics=['mse'])\n",
    "# Train Network\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=5,verbose=True),\n",
    "            ModelCheckpoint(filepath='/home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout/weights-{epoch:02d}-{val_loss:.2f}.hdf5',monitor='val_loss',save_best_only=True,verbose=True),\n",
    "            EarlyStopping(patience=13,restore_best_weights=True)]\n",
    "model.fit(training_data,training_data,batch_size=256,validation_split=0.2,epochs=1000,callbacks=callbacks)\n",
    "# Get outputs\n",
    "# SPE statistic\n",
    "# Hotelling's T^2 Statistic\n",
    "# Percentile Tresholds\n",
    "# Unified Statistic\n",
    "# Load Testing Data\n",
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
