{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Dense,Dropout,BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for random number generators for reproducable results\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = pyreadr.read_r(\"/home/shanmukh/Documents/IICT/tep-fault-detection/dataset/TEP_FaultFree_Training.RData\")\n",
    "df = data['fault_free_training']\n",
    "training_data = df.drop([\"faultNumber\",\"simulationRun\",\"sample\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Normalization\n",
    "# 0 mean \n",
    "# 1 std\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(training_data)\n",
    "normalized = scaler.transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Autoencoder model\n",
    "def autoencoder(dropout=0.25,regularization = 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,input_dim=52,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(64,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(64,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(32, name='latent_space',activity_regularizer=l1(regularization)))\n",
    "    \n",
    "    model.add(Dense(64,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(dropout))\n",
    "    model.add(Dense(64,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(dropout))\n",
    "    model.add(Dense(128,activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(dropout))\n",
    "    model.add(Dense(52))\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shanmukh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/100\n",
      "200000/200000 [==============================] - 28s 139us/step - loss: 111.8162 - mean_squared_error: 314460.9260 - val_loss: 4.4699 - val_mean_squared_error: 121.1594\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.46986, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout_no_tanh/weights-01-4.47.hdf5\n",
      "Epoch 2/100\n",
      "200000/200000 [==============================] - 20s 101us/step - loss: 1.6468 - mean_squared_error: 29.5888 - val_loss: 5.0400 - val_mean_squared_error: 399.5609\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.46986\n",
      "Epoch 3/100\n",
      "200000/200000 [==============================] - 17s 87us/step - loss: 1.5638 - mean_squared_error: 26.4811 - val_loss: 7.0070 - val_mean_squared_error: 381.3904\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.46986\n",
      "Epoch 4/100\n",
      "200000/200000 [==============================] - 30s 151us/step - loss: 1.5306 - mean_squared_error: 26.3187 - val_loss: 4.8257 - val_mean_squared_error: 181.3605\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.46986\n",
      "Epoch 5/100\n",
      "200000/200000 [==============================] - 32s 160us/step - loss: 1.5341 - mean_squared_error: 26.2916 - val_loss: 6.4477 - val_mean_squared_error: 291.8141\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.46986\n",
      "Epoch 6/100\n",
      "200000/200000 [==============================] - 31s 157us/step - loss: 1.5250 - mean_squared_error: 26.3198 - val_loss: 4.8911 - val_mean_squared_error: 170.9747\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.46986\n",
      "Epoch 7/100\n",
      "200000/200000 [==============================] - 31s 154us/step - loss: 1.2799 - mean_squared_error: 25.8624 - val_loss: 1.7222 - val_mean_squared_error: 32.0053\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.46986 to 1.72224, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout_no_tanh/weights-07-1.72.hdf5\n",
      "Epoch 8/100\n",
      "200000/200000 [==============================] - 29s 147us/step - loss: 1.2734 - mean_squared_error: 25.8699 - val_loss: 1.9647 - val_mean_squared_error: 50.4599\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.72224\n",
      "Epoch 9/100\n",
      "200000/200000 [==============================] - 31s 156us/step - loss: 1.2760 - mean_squared_error: 25.8696 - val_loss: 2.4413 - val_mean_squared_error: 93.6044\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.72224\n",
      "Epoch 10/100\n",
      "200000/200000 [==============================] - 32s 159us/step - loss: 1.2725 - mean_squared_error: 25.8550 - val_loss: 1.6213 - val_mean_squared_error: 32.9680\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.72224 to 1.62127, saving model to /home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout_no_tanh/weights-10-1.62.hdf5\n",
      "Epoch 11/100\n",
      "200000/200000 [==============================] - 32s 161us/step - loss: 1.2723 - mean_squared_error: 25.8444 - val_loss: 1.8035 - val_mean_squared_error: 46.0587\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.62127\n",
      "Epoch 12/100\n",
      "144640/200000 [====================>.........] - ETA: 8s - loss: 1.2716 - mean_squared_error: 25.8776"
     ]
    }
   ],
   "source": [
    "model = autoencoder()\n",
    "model.compile(optimizer=Adam(lr=0.01),loss=\"mae\",metrics=['mse'])\n",
    "# Train Network\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=5,verbose=True),\n",
    "            ModelCheckpoint(filepath='/home/shanmukh/Documents/IICT/tep-fault-detection/models/decoder_no_dropout_no_tanh/weights-{epoch:02d}-{val_loss:.2f}.hdf5',monitor='val_loss',save_best_only=True,verbose=True),\n",
    "            EarlyStopping(patience=13,restore_best_weights=True)]\n",
    "model.fit(training_data,training_data,batch_size=256,validation_split=0.2,epochs=100,callbacks=callbacks)\n",
    "# Get outputs\n",
    "# SPE statistic\n",
    "# Hotelling's T^2 Statistic\n",
    "# Percentile Tresholds\n",
    "# Unified Statistic\n",
    "# Load Testing Data\n",
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
